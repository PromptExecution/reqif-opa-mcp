## Codebase Patterns
- Project structure: reqif_mcp/ package for all implementation code
- Use ruff for linting (never black)
- Use PEP 484 type hints for all Python code
- Use uv/uvx for package management (never pip or poetry)
- Use fastmcp >= 0.4.0 for MCP server
- Use "returns" module for Rust-style Result/Option patterns
  - All functions that can fail return Result[SuccessType, Exception]
  - Use Success(value) and Failure(error) for returns
  - Match statements need explicit variable assignment for mypy exhaustiveness
- JSON schemas follow JSON Schema 2020-12 specification
- All schemas include $schema, $id, title, description, type, required, and properties fields
- Quality checks: `uv run mypy --strict` and `uv run ruff check` must pass

---

## 2026-01-30 - US-001
- Implemented canonical requirement record JSON schema for reqif-mcp/1
- Files changed:
  - Created schemas/requirement-record.schema.json
- **Learnings for future iterations:**
  - Schema directory established at `schemas/` for all data contract schemas
  - Requirement record schema defines the core data model that all other components depend on
  - Schema includes all required fields: uid, key, subtypes[], status enum, policy_baseline object, rubrics[], text, attrs (flexible)
  - Status enum strictly limited to: active, obsolete, draft
  - Policy baseline requires id, version, and hash for traceability
  - Rubrics require engine, bundle, package, rule fields for OPA evaluation
  - Attrs object is flexible with additionalProperties:true to allow domain-specific extensions
---

## 2026-01-30 - US-002
- Implemented requirement record validation function using jsonschema
- Files changed:
  - Created reqif_mcp/__init__.py (package initialization)
  - Created reqif_mcp/validation.py (validation module with 3 functions)
  - Created pyproject.toml (project dependencies with uv)
  - Created .python-version (Python 3.10.16)
  - Created uv.lock (dependency lockfile)
- **Learnings for future iterations:**
  - Project structure created: reqif_mcp/ package with __init__.py
  - Used uv for dependency management: `uv init`, `uv add`, `uv add --dev`
  - Validation uses jsonschema Draft202012Validator for JSON Schema 2020-12 compliance
  - Validation functions return Result[ValidationResult, Exception] using returns module
  - ValidationResult TypedDict structure: {valid: bool, errors: list[ValidationErrorDetail]}
  - ValidationErrorDetail TypedDict structure: {field: str, message: str, value: Any}
  - Three validation functions created:
    1. load_schema(path) -> loads schema from file
    2. validate_requirement_record(record, schema) -> validates record against schema
    3. validate_requirement_record_from_schema_file(record, path) -> convenience function
  - All functions use Rust-style error handling with returns module (Success/Failure)
  - Type checking: mypy with --strict flag passes (added types-jsonschema stub)
  - Linting: ruff check passes (removed unused import)
  - Match statements need explicit variable assignment before match for mypy exhaustiveness checking
---
## 2026-01-30 - US-003
- Implemented ReqIF 1.2 XML parser module
- Files changed:
  - Created reqif_mcp/reqif_parser.py (256 lines)
- **Learnings for future iterations:**
  - ReqIF 1.2 XML structure has three main sections: REQ-IF-HEADER, REQ-IF-CONTENT, REQ-IF-TOOL-EXTENSION
  - Key elements in ReqIF: SpecObjects (requirements), SpecTypes (type definitions), AttributeDefinitions, AttributeValues
  - Parser uses xml.etree.ElementTree for XML parsing (standard library, no extra deps)
  - Parser accepts both file path and XML string as input (handles Path objects and strings)
  - All parsing functions return Result[Data, Exception] for consistent error handling
  - Malformed XML caught via ET.ParseError and wrapped in ValueError with clear message
  - Invalid ReqIF structure (missing root, header, content) caught and reported via Result.Failure
  - TypedDict used for structured data (ReqIFData, SpecObject, SpecType, AttributeDefinition, AttributeValue)
  - Intermediate _ContentData TypedDict needed to satisfy mypy strict typing for complex return types
  - Text elements can be None, need explicit checks: `if elem.text else ""` pattern
  - Parser extracts identifiers, type references, attribute definitions and values
  - Supports ATTRIBUTE-DEFINITION-STRING (can be extended for Integer, Real, etc.)
  - Quality checks: mypy --strict and ruff check both pass
---

## 2026-01-30 - US-004
- Implemented ReqIF normalization module that transforms ReqIF data into canonical requirement records
- Files changed:
  - Created reqif_mcp/normalization.py (256 lines)
  - Modified reqif_mcp/__init__.py (added normalize_reqif export)
  - Modified pyproject.toml (added python-ulid dependency)
  - Modified uv.lock (updated dependencies)
- **Learnings for future iterations:**
  - Normalization module uses ULID library for stable, sortable unique identifiers
  - Main function: normalize_reqif(reqif_data, policy_baseline_id, policy_baseline_version) -> Result[list[dict], Exception]
  - Normalization strategy: build lookup maps for SpecTypes and AttributeDefinitions, then normalize each SpecObject
  - UID extraction: use ReqIF identifier if valid (alphanumeric + _-), otherwise generate ULID
  - Attribute mapping: ReqIF AttributeValues mapped to normalized fields via AttributeDefinition long_name
  - Attribute normalization: lowercase, replace spaces/hyphens with underscores
  - Subtypes extraction: check subtypes attribute, type attribute, or infer from SpecType long_name (default: ["GENERAL"])
  - Status validation: ensure status is one of active/obsolete/draft (default: "active")
  - Policy baseline: includes id, version, and computed hash (SHA256 of id:version for MVP)
  - Default rubrics: generate OPA rubric for each subtype (engine=opa, bundle=org/compliance, package=compliance.{subtype}, rule=decision)
  - Optional attrs object: only include if non-empty (severity, owner, verify_method)
  - Return type: Result[list[dict[str, Any]], Exception] for consistent error handling
  - Quality checks: mypy --strict and ruff check both pass
---

## 2026-01-30 - US-005
- Implemented requirement record integrity validation function
- Files changed:
  - Modified reqif_mcp/validation.py (added validate_requirement_integrity function, IntegrityValidationResult and IntegrityErrorDetail TypedDicts)
  - Modified reqif_mcp/__init__.py (exported new validation functions and types)
- **Learnings for future iterations:**
  - Integrity validation extends schema validation with referential checks
  - Function signature: validate_requirement_integrity(requirements: list[dict], mode: str) -> Result[IntegrityValidationResult, Exception]
  - Two validation modes: "basic" (structure only) and "strict" (adds referential integrity checks)
  - IntegrityValidationResult includes: valid (bool), errors (list), warnings (list)
  - UID uniqueness check uses dict to track seen UIDs and their indices
  - Policy baseline validation checks: id, version, hash fields all present and non-empty
  - Rubric validation checks: engine, bundle, package, rule fields all present and non-empty
  - Strict mode adds check for multiple policy baselines in same requirement set (warning, not error)
  - All errors include record_uid for traceability (or None for set-level errors)
  - Quality checks: mypy --strict and ruff check both pass
---

## 2026-01-30 - US-006
- Implemented FastMCP 3.0 server scaffold with HTTP and STDIO transport support
- Files changed:
  - Created reqif_mcp/server.py (FastMCP server module)
  - Created reqif_mcp/__main__.py (CLI entry point)
  - Modified reqif_mcp/__init__.py (exported server functions)
  - Modified pyproject.toml (added fastmcp>=0.4.0 dependency)
  - Modified uv.lock (updated dependencies)
- **Learnings for future iterations:**
  - FastMCP server initialization: `mcp = FastMCP("reqif-mcp", version="0.1.0")`
  - In-memory baseline store implemented as module-level dict: `_baseline_store: dict[str, list[dict[str, Any]]]`
  - Server supports both HTTP (0.0.0.0:8000) and STDIO transports via run_server(transport="http"|"stdio")
  - CLI entry point via __main__.py allows running server with: `python -m reqif_mcp [--http] [--host HOST] [--port PORT]`
  - Structured error responses use create_error_response(error) -> {error: {message, type}}
  - Baseline store provides three functions: get_baseline_by_handle (returns Result), store_baseline, clear_baseline_store
  - Tools will be registered with @mcp.tool() decorator (placeholder added for future stories)
  - Server scaffold is ready for tool implementation in US-007 and beyond
  - Quality checks: mypy --strict and ruff check both pass
---

## 2026-01-30 - US-007
- Implemented reqif.parse tool in FastMCP server
- Files changed:
  - Modified reqif_mcp/server.py (added reqif_parse tool function)
- **Learnings for future iterations:**
  - FastMCP tool registration uses @mcp.tool() decorator for automatic registration
  - Tool function signature: reqif_parse(xml_b64, policy_baseline_id="default", policy_baseline_version="1.0.0") -> dict
  - Base64 decoding pattern: base64.b64decode(xml_b64).decode("utf-8")
  - Error handling pattern: catch decode errors and return create_error_response(ValueError(...))
  - Parser function name is parse_reqif_xml (not parse_reqif) from reqif_parser module
  - Normalizer function signature: normalize_reqif(reqif_data, policy_baseline_id, policy_baseline_version)
  - Handle generation: use ULID library to generate unique sortable identifiers: str(ULID())
  - Tool returns success dict with: handle (str), requirement_count (int), policy_baseline (dict)
  - Tool returns error dict via create_error_response on parsing or normalization failure
  - Baseline storage: use store_baseline(handle, requirements) to save in-memory
  - All Result types from returns module checked with isinstance(result, Failure) pattern
  - Unwrap Success/Failure values with .unwrap() and .failure() methods
  - Quality checks: mypy --strict and ruff check both pass
---
## 2026-01-30 - US-008
- Implemented reqif.validate tool in FastMCP server
- Files changed:
  - Modified reqif_mcp/server.py (added reqif_validate tool function and import)
- **Learnings for future iterations:**
  - FastMCP tool pattern established: @mcp.tool() decorator with descriptive function name
  - Tool function signature: reqif_validate(handle: str, mode: str = "basic") -> dict[str, Any]
  - Mode parameter validation: check for valid values ("basic" or "strict") before processing
  - Error handling pattern: use get_baseline_by_handle() and check isinstance(result, Failure)
  - Validation function: validate_requirement_integrity(requirements, mode) from validation module
  - Return structured validation report: {valid, errors[], warnings[], mode, requirement_count}
  - Import pattern: add validate_requirement_integrity import to existing imports
  - Quality checks: mypy --strict and ruff check both pass
---

## 2026-01-30 - US-009
- Implemented reqif.query tool in FastMCP server for querying requirements with filtering and pagination
- Files changed:
  - Modified reqif_mcp/server.py (added reqif_query tool function)
- **Learnings for future iterations:**
  - FastMCP tool pattern: @mcp.tool() decorator with descriptive function name
  - Query tool signature: reqif_query(handle, subtypes=None, status=None, limit=None, offset=0) -> dict
  - Handle is required parameter (baseline identifier from reqif.parse)
  - Filtering pattern: retrieve baseline, apply filters sequentially, then paginate
  - Subtypes filter uses AND logic: all(subtype in req.get("subtypes", []) for subtype in subtypes)
  - Status filter validates against enum: "active", "obsolete", "draft"
  - Pagination: slice filtered_requirements[offset:offset+limit] or [offset:] if limit is None
  - Return structure: {requirements[], total_count, returned_count, offset}
  - Empty result set returns empty array (not error) - this is intentional design
  - Type hints: use list[str] | None for optional list parameters (Python 3.10+)
  - Quality checks: mypy --strict and ruff check both pass
---

## 2026-01-30 - US-010
- Implemented deterministic ordering for query results
- Files changed:
  - Modified reqif_mcp/server.py (added sorted() call in reqif_query function)
  - Modified ralph/prd.json (marked US-010 as passes: true)
- **Learnings for future iterations:**
  - Deterministic ordering achieved by sorting filtered_requirements by uid (ascending) before pagination
  - Sort applied after all filters but before pagination to ensure consistent subsets with offset
  - Python sorted() with key=lambda pattern: sorted(list, key=lambda item: item.get("uid", ""))
  - Empty string default for missing uid ensures consistent sorting even for malformed records
  - Sort position in query flow: retrieve → filter by subtypes → filter by status → sort → paginate
  - Same query with same filters now guaranteed to return results in same order
  - Quality checks: mypy --strict and ruff check both pass
---
## 2026-01-30 - US-011
- Implemented agent facts JSON schema for facts/1 data contract
- Files changed:
  - Created schemas/agent-facts.schema.json
- **Learnings for future iterations:**
  - Agent facts schema defines standard output format for all agents
  - Schema includes four required top-level fields: target, facts, evidence[], agent
  - Target structure captures what was analyzed: repo, commit, build (all required, extensible with additionalProperties)
  - Facts object has flexible schema (additionalProperties: true) to allow arbitrary fact types from different agents
  - Evidence array supports multiple evidence types: code_span, artifact, log, metric
  - Evidence items require type and uri; optional fields include startLine, endLine (for code spans), hash (for artifacts)
  - Agent metadata requires name and version; optional rubric_hint field suggests which OPA package to use
  - Schema uses JSON Schema 2020-12 specification with $schema, $id, title, description
  - Evidence URI pattern: use stable addressable URIs like repo://, artifact://, file://
  - Agents NEVER decide pass/fail - they only produce facts and evidence; OPA makes decisions
  - Quality checks: mypy --strict and ruff check both pass (no Python code added, schema only)
---

## 2026-01-30 - US-012
- Implemented OPA evaluation input and output JSON schemas for policy evaluation
- Files changed:
  - Created schemas/opa-input.schema.json
  - Created schemas/opa-output.schema.json
- **Learnings for future iterations:**
  - OPA input schema defines three required top-level fields: requirement, facts, context
  - Input requirement field embeds full reqif-mcp/1 requirement record structure
  - Input facts field embeds full facts/1 agent facts structure
  - Input context field has flexible schema (additionalProperties: true) for evaluation-specific parameters
  - OPA output schema defines comprehensive decision structure with seven status values
  - Status enum: pass, fail, conditional_pass, inconclusive, not_applicable, blocked, waived
  - Output includes score (0.0-1.0) and confidence (0.0-1.0) numeric fields for quantitative analysis
  - Criteria array breaks down decision into individual criterion evaluations (id, status, weight, message, evidence[])
  - Criterion status uses simplified enum: pass, fail, na (not applicable)
  - Criterion evidence field contains indices into facts.evidence[] array for traceability
  - Reasons array provides human-readable explanation strings for the overall decision
  - Policy provenance required: bundle (identifier), revision (version), hash (content hash for verification)
  - These schemas establish the contract between agent facts, OPA evaluation, and SARIF reporting
  - Quality checks: mypy --strict and ruff check both pass (no Python code added, schema only)
---
## 2026-01-30 - US-013
- Implemented OPA bundle template structure with example policy for CYBER subtype
- Files changed:
  - Created opa-bundles/example/policy/cyber.rego (261 lines)
  - Created opa-bundles/example/data/thresholds.json (example lookup table)
  - Created opa-bundles/example/.manifest (bundle metadata)
  - Modified .gitignore (allowed .manifest files in opa-bundles/)
- **Learnings for future iterations:**
  - OPA bundle structure: policy/ directory for .rego files, data/ directory for JSON data files, .manifest file for metadata
  - Rego policy package structure: package cyber.access_control.v3 (corresponds to rubric package in requirement records)
  - OPA input structure: input.requirement (full requirement record), input.facts (full agent facts), input.context (flexible)
  - OPA output structure: decision object with status (enum: pass/fail/conditional_pass/inconclusive/not_applicable/blocked/waived), score (0.0-1.0), confidence (0.0-1.0), criteria[], reasons[], policy provenance
  - Criteria array: each criterion has id, status (pass/fail/na), weight, message, evidence[] (indices into facts.evidence[])
  - Policy evaluation pattern: evaluate multiple criteria, aggregate results, determine overall status, calculate confidence
  - Status determination: pass if no failures + at least one pass, fail if any criterion failed, not_applicable if all criteria na, inconclusive otherwise
  - Confidence calculation heuristic: based on evidence count (0=0.3, 1-2=0.6, 3-4=0.8, 5+=1.0)
  - Data files provide lookup tables: thresholds.json includes crypto settings, input validation rules, access control parameters, scoring weights
  - Bundle .manifest format: JSON with revision, roots[] (package roots), metadata (bundle id, description, authors, subtypes)
  - Gitignore issue: *.manifest pattern blocked OPA .manifest files - added exception rule !opa-bundles/**/.manifest
  - Rego built-in functions: strings.lower() for case-insensitive matching, contains() for substring search, count() for array length, object.get() for safe field access
  - Policy uses default decision rule for when no specific rules match (returns inconclusive status)
  - Quality checks: mypy --strict and ruff check both pass (no Python code added, only Rego and JSON)
---
## 2026-01-30 - US-014
- Implemented OPA evaluator module for executing policy evaluations
- Files changed:
  - Created reqif_mcp/opa_evaluator.py (236 lines)
  - Modified reqif_mcp/__init__.py (exported OPA evaluator functions)
- **Learnings for future iterations:**
  - OPA evaluator module provides four main functions:
    1. load_bundle_manifest(bundle_path) -> loads .manifest file from OPA bundle directory
    2. compose_opa_input(requirement, facts, context) -> creates OPA input JSON structure
    3. evaluate_with_opa(opa_input, bundle_path, package, rule, opa_binary) -> invokes OPA subprocess
    4. evaluate_requirement(requirement, facts, bundle_path, ...) -> high-level convenience function
  - OPA invocation via subprocess: `opa eval --bundle <path> --format json --stdin-input <query>`
  - OPA eval query format: `data.{package}.{rule}` (e.g., "data.cyber.access_control.v3.decision")
  - OPA output structure: {"result": [{"expressions": [{"value": <decision>}]}]} - need to extract nested value
  - OPA subprocess configured with 30 second timeout to prevent hanging
  - Module supports configurable OPA binary path (defaults to "opa" in PATH)
  - Package can be auto-detected from requirement.rubrics[0].package if not specified
  - All functions return Result[T, Exception] for consistent error handling
  - Error cases handled: bundle not found, manifest missing, OPA binary not found, timeout, invalid JSON output
  - Quality checks: mypy --strict and ruff check both pass
---
## 2026-01-31 - US-015
- Implemented OPA output schema validation
- Files changed:
  - Modified reqif_mcp/opa_evaluator.py (added validate_opa_output function, integrated into evaluate_with_opa)
  - Modified reqif_mcp/__init__.py (exported validate_opa_output)
  - Modified reqif_mcp/reqif_parser.py (fixed REQIF_NS undefined variable bug)
  - Modified pyproject.toml (fixed duplicate [project] header)
- **Learnings for future iterations:**
  - OPA output validation uses jsonschema Draft202012Validator for schema validation
  - validate_opa_output() function validates against schemas/opa-output.schema.json by default
  - Validation checks: status enum, required fields (status, criteria, reasons, policy), policy provenance fields
  - Invalid OPA output returns Failure(ValueError(...)) with clear message, never crashes
  - Validation integrated into evaluate_with_opa() before returning decision to caller
  - Schema path resolution: uses Path(__file__).parent.parent / "schemas" / "opa-output.schema.json"
  - jsonschema ValidationError converted to ValueError with clear field path and message
  - Manual checks supplement schema validation for critical fields like status enum
  - pyproject.toml formatting: no indentation, flat structure (was incorrectly nested)
  - Quality checks: mypy --strict and ruff check both pass
---

## 2026-01-31 - US-016
- Implemented OPA decision logging with JSONL append-only audit trail
- Files changed:
  - Created reqif_mcp/decision_logger.py (decision logging module with ULID)
  - Modified reqif_mcp/opa_evaluator.py (integrated decision logging into evaluate_requirement)
  - Modified reqif_mcp/__init__.py (exported decision logging functions)
  - Created evidence_store/ directory structure (decision_logs/, events/, sarif/)
  - Modified README.md (added log rotation strategy documentation)
  - Modified ralph/prd.json (marked US-016 as passes: true)
- **Learnings for future iterations:**
  - Decision logging module provides three functions: create_decision_log_entry, append_decision_log, log_evaluation
  - DecisionLogEntry TypedDict structure: evaluation_id, timestamp, requirement, facts, context, decision, policy
  - Evaluation IDs use ULID for unique, sortable identifiers (same as baseline handles)
  - Decision logs written to evidence_store/decision_logs/decisions.jsonl by default (append-only JSONL)
  - Log file path configurable via log_file_path parameter
  - Decision logging integrated into evaluate_requirement with enable_decision_logging flag (defaults to True)
  - Log failures are non-fatal - print warning and continue evaluation (don't fail the gate)
  - Evidence store directory structure: evidence_store/{decision_logs/, events/, sarif/}
  - Log rotation strategy documented in README section 9.1 (external tools like logrotate for production)
  - MVP: single file without automatic rotation; production should use external rotation
  - Decision logs are immutable audit trail - never modify without governance approval
  - Quality checks: mypy --strict and ruff check both pass
---
